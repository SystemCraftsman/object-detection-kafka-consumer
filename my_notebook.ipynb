{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "KUu4vOt5zI9d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4XGxDrCkeip"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "6cPY9Ou4sWs_"
   },
   "outputs": [],
   "source": [
    "#@title Imports and function definitions\n",
    "\n",
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time\n",
    "\n",
    "# Print Tensorflow version\n",
    "print(f'Tensorflow Version {tf.__version__}')\n",
    "\n",
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGkrXGy62409"
   },
   "source": [
    "## Example use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlA3CftFpRiW"
   },
   "source": [
    "### Helper functions for downloading images and for visualization.\n",
    "\n",
    "Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9IwDpOtpIHW"
   },
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "  fig = plt.figure(figsize=(20, 15))\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image)\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = top + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                    (left + text_width, text_bottom)],\n",
    "                   fill=color)\n",
    "    draw.text((left + margin, text_bottom - text_height - margin),\n",
    "              display_str,\n",
    "              fill=\"black\",\n",
    "              font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "  colors = list(ImageColor.colormap.values())\n",
    "\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                              25)\n",
    "  except IOError:\n",
    "    print(\"Font not found, using default font.\")\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  for i in range(min(boxes.shape[0], max_boxes)):\n",
    "    if scores[i] >= min_score:\n",
    "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                     int(100 * scores[i]))\n",
    "      color = colors[hash(class_names[i]) % len(colors)]\n",
    "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "      draw_bounding_box_on_image(\n",
    "          image_pil,\n",
    "          ymin,\n",
    "          xmin,\n",
    "          ymax,\n",
    "          xmax,\n",
    "          color,\n",
    "          font,\n",
    "          display_str_list=[display_str])\n",
    "      np.copyto(image, np.array(image_pil))\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D19UCu9Q2-_8"
   },
   "source": [
    "## Apply module\n",
    "\n",
    "Load a public image from Open Images v4, save locally, and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "YLWNhjUY1mhg"
   },
   "outputs": [],
   "source": [
    "image_path = \"images/Naxos_Taverna.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-VdfLbC1w51"
   },
   "source": [
    "Pick an object detection module and apply on the downloaded image. Modules:\n",
    "* **FasterRCNN+InceptionResNet V2**: high accuracy,\n",
    "* **ssd+mobilenet V2**: small and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uazJ5ASc2_QE"
   },
   "outputs": [],
   "source": [
    "model_dir = 'models/openimages_v4_ssd_mobilenet_v2_1'\n",
    "saved_model = tf.saved_model.load(model_dir)\n",
    "model = saved_model.signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znW8Fq1EC0x7"
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwGJV96WWBLH"
   },
   "outputs": [],
   "source": [
    "def run_detector(detector, path):\n",
    "  img = load_img(path)\n",
    "\n",
    "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  start_time = time.time()\n",
    "  result = detector(converted_img)\n",
    "  end_time = time.time()\n",
    "\n",
    "  result = {key:value.numpy() for key,value in result.items()}\n",
    "\n",
    "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "  print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "  image_with_boxes = draw_boxes(\n",
    "      img.numpy(), result[\"detection_boxes\"],\n",
    "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "  display_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vchaUW1XDodD"
   },
   "outputs": [],
   "source": [
    "run_detector(model, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "model_dir = 'models/openimages_v4_ssd_mobilenet_v2_1'\n",
    "saved_model = tf.saved_model.load(model_dir)\n",
    "detector = saved_model.signatures['default']\n",
    "\n",
    "\n",
    "def predict(body):\n",
    "    base64img = body.get('image')\n",
    "    img_bytes = base64.decodebytes(base64img.encode())\n",
    "    detections = detect(img_bytes)\n",
    "    cleaned = clean_detections(detections)\n",
    "    \n",
    "    return { 'detections': cleaned }\n",
    "\n",
    "\n",
    "def detect(img):    \n",
    "    image = tf.image.decode_jpeg(img, channels=3)\n",
    "    converted_img  = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "    result = detector(converted_img)\n",
    "    num_detections = len(result[\"detection_scores\"])\n",
    "    \n",
    "    output_dict = {key:value.numpy().tolist() for key, value in result.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def clean_detections(detections):\n",
    "    cleaned = []\n",
    "    num_detections = detections['num_detections']\n",
    "\n",
    "    for i in range(0, num_detections):\n",
    "        d = {\n",
    "            'box': {\n",
    "                'yMin': detections['detection_boxes'][i][0],\n",
    "                'xMin': detections['detection_boxes'][i][1],\n",
    "                'yMax': detections['detection_boxes'][i][2],\n",
    "                'xMax': detections['detection_boxes'][i][3]\n",
    "            },\n",
    "            'class': detections['detection_class_entities'][i].decode('utf-8'),\n",
    "            'label': detections['detection_class_entities'][i].decode('utf-8'),\n",
    "            'score': detections['detection_scores'][i],\n",
    "        }\n",
    "        cleaned.append(d)\n",
    "    return cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def meh(detector, path):\n",
    "    img = load_img(path)\n",
    "    \n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    return result\n",
    "    num_detections = len(result[\"detection_scores\"])\n",
    "    \n",
    "    output_dict = {key:value.numpy().tolist() for key,value in result.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "x = meh(model, image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = {key:value for key,value in x.items()}\n",
    "type(y['detection_scores'][0].numpy())\n",
    "\n",
    "# type(y['detection_scores'][0])\n",
    "\n",
    "# help(y['detection_scores'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detect(model, image_path)\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_dict = clean_detections(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "type(detections_dict[0]['box']['yMin'].item())\n",
    "# json.dumps(detections_dict[0]['box']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.1\n",
    "x.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import predict, detect\n",
    "\n",
    "\n",
    "# with open('requests/request-1.json') as json_file:\n",
    "#     data = json.load(json_file)\n",
    "\n",
    "# data\n",
    "# predict(data)\n",
    "img = tf.io.read_file(image_path)\n",
    "detect(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "base64img = open('images/Naxos_Taverna.base64', \"r\").read()\n",
    "img_bytes = base64.decodebytes(base64img.encode())\n",
    "img2 = tf.image.decode_jpeg(img_bytes, channels=3)\n",
    "img2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict({'image': base64img})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUUY3nfRX7VF"
   },
   "source": [
    "### More images\n",
    "Perform inference on some additional images with time tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rubdr2JXfsa1"
   },
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    'images/1024px-Biblioteca_Maimónides,_Campus_Universitario_de_Rabanales_007.jpg',\n",
    "    'images/image1.jpg',\n",
    "    'images/image2.jpg',\n",
    "    'images/Naxos_Taverna.jpg',\n",
    "    'images/The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg',\n",
    "    'images/The_smaller_British_birds_(8053836633).jpg'\n",
    "  ]\n",
    "\n",
    "def detect_img(image_path):\n",
    "  start_time = time.time()\n",
    "#   image_path = download_and_resize_image(image_url, 640, 480)\n",
    "  run_detector(model, image_path)\n",
    "  end_time = time.time()\n",
    "  print(\"Inference time:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otPnrxMKIrj5"
   },
   "outputs": [],
   "source": [
    "detect_img(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5F7DkD5NtOx"
   },
   "outputs": [],
   "source": [
    "detect_img(image_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZ18R7dWNyoU"
   },
   "outputs": [],
   "source": [
    "detect_img(image_paths[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_img(image_paths[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_img(image_paths[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
